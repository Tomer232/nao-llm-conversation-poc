# audio/tts_openai.py

import os
import tempfile
import wave
import contextlib
import winsound

from openai import OpenAI

client = OpenAI()

# All voices that are actually supported by the API (per the error you saw).
SUPPORTED_TTS_VOICES = {
    "alloy",
    "echo",
    "fable",
    "onyx",
    "nova",
    "shimmer",
    "coral",
    "verse",
    "ballad",
    "ash",
    "sage",
    "marin",
    "cedar",
}

DEFAULT_TTS_VOICE = "onyx"
TTS_MODEL = "gpt-4o-mini-tts"


def _log(logger, msg):
    try:
        logger(msg)
    except Exception:
        # Fallback to print if the provided logger fails for any reason
        print(msg)


def _normalize_voice(raw_voice, logger):
    """
    Take whatever 'voice' value we got and:
      - if it's valid, return it as-is;
      - if it's invalid/None, fall back to DEFAULT_TTS_VOICE and log a warning.
    """
    if not isinstance(raw_voice, str) or not raw_voice.strip():
        _log(logger, f"[TTS] No voice specified, falling back to default '{DEFAULT_TTS_VOICE}'.")
        return DEFAULT_TTS_VOICE

    voice = raw_voice.strip()

    if voice not in SUPPORTED_TTS_VOICES:
        supported_str = ", ".join(sorted(SUPPORTED_TTS_VOICES))
        _log(
            logger,
            f"[TTS] Invalid voice '{voice}' received. "
            f"Falling back to '{DEFAULT_TTS_VOICE}'. "
            f"Supported voices: {supported_str}",
        )
        return DEFAULT_TTS_VOICE

    return voice


def _extract_text_and_voice_from_args_kwargs(args, kwargs, logger):
    """
    Be very forgiving about how speak_text is called,
    so we don't break existing code.
    We only *require* text; everything else is best-effort.
    """
    text = None
    voice = None

    # 1. Text: first positional arg or explicit 'text' kw
    if args:
        text = args[0]
    if "text" in kwargs and kwargs["text"]:
        text = kwargs["text"]

    # 2. Voice: kwarg 'voice' if present
    if "voice" in kwargs and isinstance(kwargs["voice"], str):
        voice = kwargs["voice"]

    # 3. Or second positional arg, if it's a string
    elif len(args) >= 2 and isinstance(args[1], str):
        voice = args[1]

    # 4. Or from a 'settings' object / dict
    elif "settings" in kwargs and kwargs["settings"] is not None:
        settings = kwargs["settings"]
        if isinstance(settings, dict):
            voice = settings.get("tts_voice") or settings.get("voice")
        else:
            # Generic object with attributes
            voice = getattr(settings, "tts_voice", None) or getattr(settings, "voice", None)

    # 5. Fallback voice handled later by _normalize_voice
    return text, voice


def speak_text(*args, **kwargs):
    """
    Main TTS entry point.

    It is intentionally tolerant to how it is called, to avoid breaking existing code.
    Typical use patterns that will work:

        speak_text("Hello world", voice="onyx")
        speak_text("Hello world", settings=settings_obj)
        speak_text("Hello world")  # uses default voice

    Extra kwargs (e.g., 'playback_mode', 'simulation', 'nao_proxy', etc.) are ignored.
    """

    logger = kwargs.get("logger", print)

    # Get text + (possibly) voice from whatever the caller passes.
    text, raw_voice = _extract_text_and_voice_from_args_kwargs(args, kwargs, logger)

    if not text or not str(text).strip():
        _log(logger, "[TTS] No text provided for synthesis; skipping TTS.")
        return

    voice = _normalize_voice(raw_voice, logger)

    try:
        # Request audio from OpenAI Audio API
        response = client.audio.speech.create(
            model=TTS_MODEL,
            voice=voice,
            input=str(text),
            response_format="wav",  # ensure we get real WAV back
        )

        # Save to a temporary WAV file
        fd, tmp_path = tempfile.mkstemp(suffix=".wav")
        os.close(fd)  # we'll reopen it with wave
        response.stream_to_file(tmp_path)

        # Inspect WAV properties for debugging
        with contextlib.closing(wave.open(tmp_path, "rb")) as wf:
            channels = wf.getnchannels()
            rate = wf.getframerate()
            sampwidth = wf.getsampwidth()
            frames = wf.getnframes()

        _log(
            logger,
            f"[TTS] Voice={voice}, WAV: channels={channels}, rate={rate}, width={sampwidth}, frames={frames}",
        )
        _log(logger, f"[TTS] Saved WAV to: {tmp_path}")

        # Play via Windows sound API (simulation / PC speakers)
        try:
            _log(logger, f"[TTS] Playing via winsound.PlaySound: {tmp_path}")
            winsound.PlaySound(tmp_path, winsound.SND_FILENAME)
            _log(logger, "[TTS] PlaySound finished")
        finally:
            # Clean up file
            try:
                os.remove(tmp_path)
            except OSError:
                pass

    except Exception as e:
        # If the voice is invalid, the API returns the exact 400 you saw.
        # Because we already normalized the voice above, we should not hit this
        # anymore unless something upstream is very broken.
        _log(logger, f"[TTS] Error during synthesis: {e}")
        _log(logger, f"[TTS] Fallback, text was: {text}")
        # No re-raise; we just skip audio but keep the loop alive.
        return
